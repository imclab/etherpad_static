<!doctype html>
<html lang="en">
<head>
<title>feedback_research</title>
<meta charset="utf-8">
<style> * { font-family: arial, sans-serif;
font-size: 13px;
line-height: 17px; }ul.indent { list-style-type: none; }ol { list-style-type: decimal; }ol ol { list-style-type: lower-latin; }ol ol ol { list-style-type: lower-roman; }ol ol ol ol { list-style-type: decimal; }ol ol ol ol ol { list-style-type: lower-latin; }ol ol ol ol ol ol{ list-style-type: lower-roman; }ol ol ol ol ol ol ol { list-style-type: decimal; }ol  ol ol ol ol ol ol ol{ list-style-type: lower-latin; }</style>
</head>
<body>Feedback Research<br>October 30, 2012, Vanessa Gennarelli<br>Research is up on Dropbox: <a href="https&#x3a;&#x2F;&#x2F;www&#x2e;dropbox&#x2e;com&#x2F;home&#x2F;Public&#x2F;Feedback&#x25;20Research">https:&#x2F;&#x2F;www.dropbox.com&#x2F;home&#x2F;Public&#x2F;Feedback%20Research</a><br><a href="http&#x3a;&#x2F;&#x2F;www&#x2e;ted&#x2e;com&#x2F;talks&#x2F;daphne&#x5f;koller&#x5f;what&#x5f;we&#x5f;re&#x5f;learning&#x5f;from&#x5f;online&#x5f;education&#x2e;html">http:&#x2F;&#x2F;www.ted.com&#x2F;talks&#x2F;daphne_koller_what_we_re_learning_from_online_education.html</a><br><br>Findings and suggestions:<br><ul class="bullet"><li>We haven&#x27;t done enough to reward people for giving feedback--their average score reported, how many reviews they&#x27;ve done, last review they&#x27;ve left (to encourage people to continue to leave reviews)</li><li>Train for suggestive and reinforcing feedback--it both improves the project and keeps folks engaged</li><li>We should connect and sustain the interaction between feedback giver and receiver--it has pedagogical value for learners to reframe their ideas, and for iteration</li><li>I&#x27;ve disparaged voting up in the past, but the voting up of good, solid feedback can help the learner direct their efforts towards what counsel to listen to.</li><li>Feedback will trend toward the positive (see examples from ebay)--how can we finesse the positivity bias into reinforcing feedback?</li><li>What do we think of course organizers rating n00b&#x27;s comments?</li><li>A design that supports iteration--what do we think about a &quot;Projects&quot; tab and an &quot;Open Questions&quot; tab? How could those features work together to support getting the feedback you need quickly and show off the projects you do&#x2F;are proud of&#x2F;elicit the sort of reinforcing feedback that keeps folks engaged?</li></ul><br>Questions:<br><ul class="bullet"><li>How do we define &quot;feedback&quot; as different from conversation?</li><li>What makes people give feedback?<ul class="bullet"><li>In online communities, many of the incentives that work in traditional institutional education fall away.</li></ul></li><li>What are the differenet types of feedback and which are we most interested in?&nbsp;<ul class="bullet"><li>&quot;Applaus&quot; (deviantart, pinterest, etc.)</li></ul></li><li>Who gets feedback? (What&#x27;s the distribution of feedback?)<ul class="bullet"><li>E.g. deviantart, popular items get a lot of feedback, most items get no feedback</li></ul></li><li>Challenge: scaling the expert feedback</li><li>Critique - the value of hard critique, see Paul Tough&#x27;s book</li><li>Is there value in observing feedback that others get for their work? (The studio model)</li></ul><br>Notes<br><br>Tseng &amp; Tsai:<br><ul class="bullet"><li>&quot;The peer assessment activities consisted of three rounds, and each of the students acted as an author and a reviewer. The scores determined by the learning peers were highly correlated with those marked by the experts, indicating that peer assessment in high school could be perceived as a valid assessment method.&quot;</li><li>184 10th-grade students (16-year-olds) from four different classes in a school in Taiwan.</li><li>3 round model: <a href="http&#x3a;&#x2F;&#x2F;cl&#x2e;ly&#x2F;KYEM">http:&#x2F;&#x2F;cl.ly&#x2F;KYEM</a></li><li>4 types of feedback<ul class="bullet"><li>Reinforcing: positively expressed feedback</li><li>Didactic: lecture tone</li><li>Suggestive: hints</li><li>Corrective: this is wrong</li></ul></li><li>Each type had an impact on student performance:&nbsp;<ul class="bullet"><li>Suggestive feedback was positively correlated with their performance in all dimensions (r = 0.18, 0.25 and 0.21 for Creativity, Relevance, and Feasibility, respectively, p &lt; 0.05)&nbsp;</li><li>Reinforcing feedback of the first round was positively correlated with students&#8217; scores on the three dimensions of the second (r = 0.38, 0.49 and 0.38 for Creativity, Relevance, and Feasibility, respectively, p &lt; 0.01)&nbsp;</li><li>These findings suggested that Reinforcing and Suggestive feedback should be constructive in students&#8217; develop- ment of their work, while feedback of lengthy explanation with a didactic tone produced negative relationships to students&#8217; project performance.</li><li><a href="http&#x3a;&#x2F;&#x2F;cl&#x2e;ly&#x2F;KY7K">http:&#x2F;&#x2F;cl.ly&#x2F;KY7K</a></li></ul></li></ul><br>Fan:<br><ul class="bullet"><li>Address cheating and fraud in reputation management on the internet</li><li>Ebay sellers: A numerical rating is associated with the comment, indicating whether the comment is positive (+1), negative (-1), or neutral (0). But &quot;In [22], empirical results show that eBay&#8217;s system does not provide sustained incentives for reputable sellers to provide honest quality over time.&quot;</li><li>2 models to keep folks honest--<ul class="bullet"><li>Average rating</li><li>Cumulative rating</li><li>&quot;Under both mechanisms, sellers will lose incentives when their reputation scores are high enough and the transaction history is long enough.&quot;</li></ul></li><li>Recommendations--include recency of review, make it difficult for folks to change identity</li></ul><br>Preece:<br><ul class="bullet"><li>Evaluates online communities in terms of:<ul class="bullet"><li>Sociability: number of participants in a community, the number of messages per unit of time, members&#8217; satisfaction, and some less obvious measures such as amount of reciprocity, the number of on-topic messages, trustworthiness&nbsp;</li><li>Usability: numbers of errors, productivity, user satisfaction</li></ul></li><li>Reciprocity important to sociability--every feedback feature should prompt more feedback (ie, if you get reviewed, feature should prompt you to review someone else)</li></ul><br>Forte:<br><ul class="bullet"><li>45 students used wikipedia to improve writing</li><li>Fear of submission for peer review--my work isn&#x27;t good enough</li><li>Peer review makes a learner aware of an audience &amp; engage the wider public</li><li>Prompts learners to have strategies for their ideas</li><li>&quot;It appears that <em>affective response </em>to others&#8217; views was what influenced their writing, especially in the case of the feminist. Her learning experience was only obtainable through direct questioning.&quot;</li></ul><br>Dellarocas:<br><ul class="bullet"><li>Ebay:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>* Buyers left feedback on sellers 52.1% of the time; sellers on buyers 60.6% of the time.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li><li>* Feedback is overwhelmingly positive; of feed- back provided by buyers, 99.1% of comments were positive, 0.6%were negative, and 0.3%were neutral.&nbsp;</li><li>&quot;In general, reputation effects benefit the most patient player in the game: The player who has the longest time horizon (discounts future payoffs less) is usually the one who is able to reap the benefits of reputation.&quot;</li></ul><br>Lin:<br><br>In this study, the web-based peer assessment was a two-stage compulsory evaluation that partially substituted for teacher assessment. During the process, a student submitted assignments in HTML format which were then anonymously uploaded through a web-based peer assessment system, named Networked Peer&nbsp;<br><br>Lampe:<br><ul class="bullet"><li>&quot;A further method of shaping new user behavior is the use of feedback provided by the larger community, often in the form of rating systems that provide evaluations of new contributions.&quot;&nbsp;</li><li>&quot;Slashdot has developed a system of distributed moderation by which experienced members of the site provide feedback in the form of ratings about the quality of comments posted to its discussion forums.&quot;</li><li>&quot;Butler [2] similarly found that more active listserv&#8217;s not only had more users entering the discussion, but that they lost users at a greater rate than smaller structures.&quot;&nbsp;</li><li>&quot;Each posted comment message has a current score, from &#8211;1 to +5. Upon reading a comment, a moderator can expend a point in order to raise or lower the comment&#8217;s score by 1. Users choose from a list of descriptors for the comments, such as &#8220;Off-topic&#8221;, &#8220;Troll&#8221;, &#8220;Insightful&#8221;, &#8220;Funny&#8221;, or &#8220;Overrated&#8221;, with each comment type carrying with it an inherent -1 or +1 moderation.&quot;</li><li>&quot;New users who received no moderation were less likely to make a second comment than users who received either positive or negative initial feedback through moderation. Even when a user receives feedback on their first comment, lack of feedback on the second is associated with approximately 30% of users to ceasing commenting.&quot;</li><li>&quot;There is some indication that receiving two negative moderations in a row make it unlikely that a user will receive a positive moderation.&quot;</li></ul><br><br>REFERENCES<br><br>Dellarocas, C. (2003). The digitization of word of mouth: Promise and challenges of online feedback mechanisms. <em>Management science</em>, <em>49</em>(10), 1407-1424.<br><br>Forte, A., &amp; Bruckman, A. (2006, June). From Wikipedia to the classroom: exploring online publication and learning. In <em>Proceedings of the 7th international conference on Learning sciences</em> (pp. 182-188). International Society of the Learning Sciences.<br><br>Lampe, C., &amp; Johnston, E. (2005, November). Follow the (slash) dot: effects of feedback on new members in an online community. In <em>Proceedings of the 2005 international ACM SIGGROUP conference on Supporting group work</em> (pp. 11-20). ACM.<br><br>Ming Fan, Yong Tan, and Andrew B. Whinston (2005). &quot;Evaluation and Design of Online Cooperative Feedback Mechanisms for Reputation Management.&quot; <em>IEEE Transactions on Knowledge and Data Engineering</em>. 17.3.<br><br>Preece, J. (2001). Sociability and usability in online communities: Determining and measuring success. <em>Behaviour &amp; Information Technology</em>, <em>20</em>(5), 347-356.<br><br>Scardamalia, M. (2004). CSILE&#x2F;Knowledge Forum&#174;. In Education and technology: An encyclopedia (pp. 183-192). Santa Barbara: ABC-CLIO.<br><br>Sheng-Chau Tseng, Chin-Chung Tsai (2007). &quot;On-line peer assessment and the role of the peer feedback: A study of high school computer course.&quot; <em>Computers &amp; Education</em>. 49: 1161&#8211;1174.<br><br><br></body>
</html>
